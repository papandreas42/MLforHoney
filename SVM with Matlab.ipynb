{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "periodic-congress",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "naval-combat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.stats as stats\n",
    "import pywt\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sharp-cooperative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.5\n",
      "<module 'scipy' from 'D:\\\\WindowsApps\\\\anaconda\\\\envs\\\\ML_for_food\\\\lib\\\\site-packages\\\\scipy\\\\__init__.py'> 1.6.2\n",
      "<module 'pywt' from 'D:\\\\WindowsApps\\\\anaconda\\\\envs\\\\ML_for_food\\\\lib\\\\site-packages\\\\pywt\\\\__init__.py'> 1.1.1\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "print(scipy, scipy.version.version)\n",
    "print(pywt, pywt.version.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-magnet",
   "metadata": {},
   "source": [
    "# Loading the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sixth-latin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_Drive(path_to_data_folder):\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  return get_data_from_folder(os.path.join(\"/content/drive/MyDrive\", path_to_data_folder))  \n",
    "\n",
    "def get_data_from_folder( path_to_data_folder ):\n",
    "  #Each class must recide in its own folder.\n",
    "  #Returns data as (image as nparray, class)\n",
    "  #gathering classes\n",
    "  class_titles = os.listdir(path_to_data_folder)\n",
    "  classes_list = list( ( enumerate( class_titles ) ) )\n",
    "  ordered_image_names = []\n",
    "  #placing image, class identifier (from classes_list) pairs in a list named data\n",
    "  data = []\n",
    "  number_of_images = 0\n",
    "  errors = 0 \n",
    "  for gyro_class in classes_list:\n",
    "    for image_name in os.listdir( os.path.join( path_to_data_folder, gyro_class[1] ) ):\n",
    "      number_of_images+=1\n",
    "      try:\n",
    "        im = Image.open( os.path.join( path_to_data_folder, gyro_class[1] , image_name)  )\n",
    "        color_image_nparray = np.asarray( im )\n",
    "        data.append( [color_image_nparray, gyro_class[0]] )\n",
    "        ordered_image_names.append(image_name)\n",
    "      except Exception as error :\n",
    "        errors+=1\n",
    "        print( error, image_name)\n",
    "\n",
    "  return data, class_titles, ordered_image_names, ( number_of_images, errors )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-candidate",
   "metadata": {},
   "source": [
    "# Wavelet Decomposition and Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "significant-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefficients_flattend( image, wavelet, levels ):\n",
    "  #image as nparray with color\n",
    "  #flattens and groups coefficients by orientation and subband\n",
    "  #returns as  ( cAn, (cHn, cVn, cDn), … (cH1, cV1, cD1)  )\n",
    "  #                                 . \n",
    "  #                                 .     \n",
    "  #                                 . \n",
    "  #for each picture\n",
    "  #n is the level of decomposition\n",
    "  \n",
    "  pil_image = Image.fromarray(image, \"RGB\")\n",
    "  pil_gray_image = pil_image.convert(\"L\")\n",
    "  gray_img = np.asarray( pil_gray_image ) \n",
    "  decomposed = pywt.wavedec2( gray_img , wavelet, level=levels)\n",
    "\n",
    "  coeff=[]\n",
    "  for subband in range(levels+1):\n",
    "    if subband==0:\n",
    "      coeff.append(np.asarray(decomposed[subband]).flatten())\n",
    "      continue\n",
    "    orientations=[]\n",
    "    for orientation in decomposed[subband]:\n",
    "      orientations.append( np.asarray(orientation).flatten() )\n",
    "    coeff.append(orientations)    \n",
    "\n",
    "  return coeff\n",
    "\n",
    "def data_to_coeffs(data, wavelet, levels):\n",
    "  #calculates wavelet coefficients and flattens them for\n",
    "  #all of the pictures\n",
    "  #returns 2D-array (coeffs, class)\n",
    "  toReturn=[]\n",
    "  for image, class_id in data:\n",
    "      instance = get_coefficients_flattend(image, wavelet, levels), class_id\n",
    "      toReturn.append(instance)\n",
    "  return toReturn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-homework",
   "metadata": {},
   "source": [
    "# Goodness of fit check with different distributions through Qqplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-emperor",
   "metadata": {},
   "source": [
    "This is done to see which distribution is more suitable for a given image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-bristol",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qqplots_of_image(image, wavelet, levels, dist):\n",
    "  #image as nparray with color\n",
    "  coeffs=get_coefficients_flattend(image, wavelet, levels)\n",
    "  alpha=0.2\n",
    "\n",
    "  fig,axes = plt.subplots(levels+1,3,figsize=(20,20), constrained_layout=True)\n",
    "  \n",
    "  #Progress\n",
    "  print(getattr(dist,\"name\"), end=\": \")\n",
    "  for m in range(levels+1):\n",
    "    if m==0:\n",
    "      sm.qqplot(coeffs[0], dist=dist, fit=True,\\\n",
    "                line=\"45\", linewidth=0.1, alpha=alpha, marker=\".\", markerfacecolor=\"black\", mew=0, ax=axes[levels-m][0])\n",
    "      axes[levels-m][0].set_title(\"Approximation\")\n",
    "      axes[levels-m][0].tick_params(direction=\"in\")\n",
    "      axes[levels-m][1].remove()\n",
    "      axes[levels-m][2].remove()\n",
    "      continue\n",
    "    for i in range(3):\n",
    "      if i==0: title=\"Level \"+str(levels-m+1)+\": Horizontal\"\n",
    "      if i==1: title=\"Level \"+str(levels-m+1)+\": Vertical\"\n",
    "      if i==2: title=\"Level \"+str(levels-m+1)+\": Diagonal\"\n",
    "\n",
    "      sm.qqplot(coeffs[m][i], dist=dist, fit=True,\\\n",
    "                line=\"45\", linewidth=0.1, alpha=alpha, marker=\".\", markerfacecolor=\"black\", mew=0, ax=axes[levels-m][i])\n",
    "      axes[levels-m][i].set_title(title)\n",
    "      axes[levels-m][i].tick_params(direction=\"in\")\n",
    "\n",
    "      #Progress\n",
    "      print(levels-m+1,i,sep=\"\", end=\" \")\n",
    "  print(\"\")\n",
    "  \n",
    "  title=\"qqplots wavelet={} levels={} dist={}\".format(wavelet, levels, getattr(dist,\"name\"))\n",
    "  fig.suptitle(title, fontsize=16)\n",
    "  fig.savefig(title)\n",
    "\n",
    "  return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-solomon",
   "metadata": {},
   "source": [
    "# Fitting distributions on the wavelet coefficients  with Matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "anticipated-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import hdf5storage\n",
    "import numpy as np\n",
    "\n",
    "def save_coeffs_for_matlab(data, wavelet, levels, save_folder_path):\n",
    "\n",
    "    all_coeffs = data_to_coeffs(data, wavelet, levels)\n",
    "    toSave ={\"wavelet\":wavelet,\\\n",
    "             \"levels\":levels,\\\n",
    "             \"coeffs\":np.array(all_coeffs) }\n",
    "\n",
    "    scipy.io.savemat(os.path.join(save_folder_path ,\"coefficients wt=\"+wavelet+\"levels=\"+str(levels)+\".mat\"), toSave)\n",
    "    return\n",
    "\n",
    "\n",
    "def save_coeffs_for_matlab_hdf5(data, wavelet, levels, save_folder_path):\n",
    "    #needed when the number of images grows large\n",
    "    all_coeffs = data_to_coeffs(data, wavelet, levels)\n",
    "    toSave ={\"wavelet\":wavelet,\\\n",
    "             \"levels\":levels,\\\n",
    "             \"coeffs\":np.array(all_coeffs, dtype=object) }\n",
    "    \n",
    "    hdf5storage.write(toSave, '.', \"coefficients wt=\"+wavelet+\"levels=\"+str(levels)+\"_hdf5 TEST object.mat\", matlab_compatible=True)    \n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def load_distribution_parameters_from_matlab(distribution_parameters_path):\n",
    "    #after fitting on matlab\n",
    "    load_dict = scipy.io.loadmat(distribution_parameters_path)\n",
    "\n",
    "    return load_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-destiny",
   "metadata": {},
   "source": [
    "# Loading distribution parameters from Matlab and preparing them to be used as SVM features in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "measured-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_for_scikit(dist_params_select_path):\\\n",
    "  #dist_params_Select is needed to save time by not fitting \n",
    "  #distributions to all subbands\n",
    "  #dist_params_select_path: path to dist_paramsSelect      \n",
    "    load_dict= load_distribution_parameters_from_matlab(dist_params_select_path)\n",
    "    \n",
    "    dist_params = load_dict[\"dist_params\"]\n",
    "    levels      = load_dict[\"levels\"].reshape(-1)[0]\n",
    "    wavelet     = load_dict[\"wavelet\"]\n",
    "    selection   = load_dict[\"selection\"]\n",
    "#    print(selection)\n",
    "    features=[]\n",
    "    labels=[]\n",
    "    column_names=[]\n",
    "    for instance_index in range(dist_params.shape[0]):\n",
    "        features_from_instance=[]\n",
    "\n",
    "        for level_index in range(dist_params[instance_index,0].shape[1]):\n",
    "            a=level_index==0\n",
    "            b=([0, 0] in selection.tolist())\n",
    "\n",
    "            if a&b:\n",
    "                for parameter_index in range(dist_params[instance_index,0][0,0][0,:].shape[0]):\n",
    "                    features_from_instance.append(dist_params[instance_index,0][0,0][0, parameter_index])\n",
    "                    \n",
    "                    if instance_index==0:\n",
    "                        column_name = \"\".join(str(a) for a in [\"Approximation\", \" Parameter \", parameter_index+1])\n",
    "                        column_names.append(column_name)\n",
    "                continue\n",
    "\n",
    "            for orientation in range(3):\n",
    "                if [levels-level_index+1, orientation+1] in selection.tolist():\n",
    "                    for parameter_index in range(dist_params[instance_index,0][0,level_index][0,:].shape[0]):\n",
    "                        features_from_instance.append(dist_params[instance_index,0][0,level_index][orientation, parameter_index])\n",
    "                        #creating column name\n",
    "                        if instance_index==0:\n",
    "                            column_name=\"\".join(str(a) for a in [\"Level \",\\\n",
    "                                                                 levels-level_index+1,\\\n",
    "                                                                 \" Orientation \",\\\n",
    "                                                                 orientation+1,\\\n",
    "                                                                 \" Parameter \",\\\n",
    "                                                                 parameter_index+1])\n",
    "                            column_names.append(column_name)\n",
    "\n",
    "        features.append(features_from_instance)\n",
    "        labels.append(dist_params[instance_index,1].reshape(-1)[0])\n",
    "    \n",
    "    #dataframe set up\n",
    "    df = pd.DataFrame(features, columns=column_names)\n",
    "    df[\"Labels\"] = labels\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-stability",
   "metadata": {},
   "source": [
    "# Visualising features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-fluid",
   "metadata": {},
   "source": [
    "We can choose 2 of the parameters and plot points (P1, P2) for each image on a 2 axis graph. If we also color code these points for the different classes we may see clusters indicating class separation in this parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-harvey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_plot_from_distribution_parameters(distribution_parameters_path,\\\n",
    "                                            save_folder_path,\\\n",
    "                                            data_path=\"D:\\\\Work and uni\\\\University\\\\ML for food authentication\\\\Data\"):\n",
    "  #dist_params from matlab  \n",
    "    \n",
    "  _ , class_titles, _, _= get_data_from_folder(data_path)\n",
    "  load_dict = load_distribution_parameters_from_matlab(distribution_parameters_path)\n",
    "  dist_params = load_dict[\"dist_params\"]\n",
    "  levels = load_dict[\"levels\"][0][0]\n",
    "  wavelet = load_dict[\"wavelet\"][0]\n",
    "  distribution = load_dict[\"distribution\"][0]\n",
    "    \n",
    "  fig, ax = plt.subplots(figsize=(10,10))\n",
    "  title=\"Plot of distribution parameters for\\nWavelet \"+wavelet+\" | Levels: \"+str(levels)+\" | Distribution: \"+ distribution\n",
    "    \n",
    "  N=len(class_titles)\n",
    "  cmap = plt.cm.jet\n",
    "  cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "  cmap = cmap.from_list('Custom cmap', cmaplist, cmap.N)\n",
    "  bounds = np.linspace(0,N,N+1)\n",
    "  norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "    \n",
    "  for instance, label in dist_params:\n",
    "      for level in np.reshape(instance, -1):\n",
    "          for orientation in level:\n",
    "              scat = ax.scatter(orientation[0], orientation[1], c=np.reshape(label,-1)[0], s=50, alpha=1, cmap=cmap, norm=norm)\n",
    "  ax.set_title(title)\n",
    "    \n",
    "  ax.set_xlabel(\"Ditribution Parameter 1\")\n",
    "  ax.set_ylabel(\"Ditribution Parameter 2\")\n",
    "  ax.tick_params(direction=\"in\")\n",
    "  cb = plt.colorbar(scat, spacing='proportional',ticks=bounds)\n",
    "  cb.set_label(\"Classes\")\n",
    "    \n",
    "  fig.savefig(os.path.join(save_folder_path, \"wt= \"+wavelet+\" levels= \"+str(levels)+\" dist=\"+load_dict[\"distribution\"][0]+\".jpeg\"), dpi=200)\n",
    "   \n",
    "  return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-prison",
   "metadata": {},
   "source": [
    "# Class populations and data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "oriented-elite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot identify image file 'E:\\\\Backups\\\\Work&Uni\\\\University\\\\ML for food authentication\\\\Data\\\\cichorium intubus pollen x 400\\\\Cichorium Intybus (Asteraceae)_1_bak.tif' Cichorium Intybus (Asteraceae)_1_bak.tif\n",
      "cannot identify image file 'E:\\\\Backups\\\\Work&Uni\\\\University\\\\ML for food authentication\\\\Data\\\\cichorium intubus pollen x 400\\\\Cichorium Intybus (Asteraceae)_3_bak.tif' Cichorium Intybus (Asteraceae)_3_bak.tif\n",
      "cannot identify image file 'E:\\\\Backups\\\\Work&Uni\\\\University\\\\ML for food authentication\\\\Data\\\\cichorium intubus pollen x 400\\\\Cichorium Intybus (Asteraceae)_bak.tif' Cichorium Intybus (Asteraceae)_bak.tif\n",
      "RESULTS\n",
      " (367, 3) \n",
      "==========================\n",
      "CLASS,titles\n",
      " ['castanea 2_pio synithismeni morfi', 'castanea sp', 'Castanea sp. new 22-7-21', 'cichorium intubus pollen x 400', 'citrus sp', 'eukalyptus sp', 'hedera helix', 'helianthus', 'heliotropium', 'hibiscous', 'inula spinoza', 'origanum', 'pinus', 'reiki_calluna vulgaris_020421', 'sonchus', 'thymus capitatus_020421', 'thymus sp pollen 20-01-21', 'tribulus sp'] \n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "#load the data\n",
    "\n",
    "data , class_titles, ordered_image_names, results= get_data_from_folder(\"E:\\\\Backups\\\\Work&Uni\\\\University\\\\ML for food authentication\\\\Data\\\\\")\n",
    "print(\"RESULTS\\n\",results,\"\\n==========================\")\n",
    "print(\"CLASS,titles\\n\",class_titles,\"\\n===========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "judicial-compensation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClassID</th>\n",
       "      <th>NumberofInstances</th>\n",
       "      <th>ClassName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>101</td>\n",
       "      <td>pinus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>101</td>\n",
       "      <td>sonchus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>thymus capitatus_020421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>hibiscous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>castanea sp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>castanea 2_pio synithismeni morfi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>hedera helix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>inula spinoza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>cichorium intubus pollen x 400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>citrus sp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>eukalyptus sp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>helianthus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>heliotropium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>origanum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>reiki_calluna vulgaris_020421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>thymus sp pollen 20-01-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ClassID  NumberofInstances                          ClassName\n",
       "0        12                101                              pinus\n",
       "1        14                101                            sonchus\n",
       "2        15                 26            thymus capitatus_020421\n",
       "3         9                  8                          hibiscous\n",
       "4         1                  5                        castanea sp\n",
       "5         0                  2  castanea 2_pio synithismeni morfi\n",
       "6         6                  2                       hedera helix\n",
       "7        10                  2                      inula spinoza\n",
       "8         3                  1     cichorium intubus pollen x 400\n",
       "9         4                  1                          citrus sp\n",
       "10        5                  1                      eukalyptus sp\n",
       "11        7                  1                         helianthus\n",
       "12        8                  1                       heliotropium\n",
       "13       11                  1                           origanum\n",
       "14       13                  1      reiki_calluna vulgaris_020421\n",
       "15       16                  1          thymus sp pollen 20-01-21"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#class populations\n",
    "class_list = list( ( enumerate( class_titles ) ) )\n",
    "\n",
    "dist_paramsSelect_folder_path = \"E:\\\\Backups\\\\Work&Uni\\\\University\\\\ML for food authentication\\\\Results_fitting\\\\dist_paramsSelect\\\\New Images\\\\\"    \n",
    "dist_paramsSelect_name = \"dist_paramsSelect wt=db4 levels=3 dist=Normal.mat\"\n",
    "dist_paramsSelect_path=os.path.join(dist_paramsSelect_folder_path, dist_paramsSelect_name)\n",
    "df = prepare_features_for_scikit(dist_paramsSelect_path)\n",
    "\n",
    "class_population=df['Labels'].value_counts(sort=True)\n",
    "\n",
    "class_dict = dict(class_list)\n",
    "df4 = pd.DataFrame(class_population)\n",
    "\n",
    "df4 = df4.reset_index()\n",
    "df4 = df4.rename(columns={\"index\":\"ClassID\", \"Labels\":\"NumberofInstances\"})\n",
    "# class_dict[df4[\"Class ID\"]]\n",
    "\n",
    "df4[\"ClassName\"] = [class_dict.get(key) for key in df4[\"ClassID\"]]\n",
    "#df4.to_csv(\"data description.csv\",index=False)\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-calendar",
   "metadata": {},
   "source": [
    "# Choosing and Balancing Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-explanation",
   "metadata": {},
   "source": [
    "Although SMVs aren't too sensitive to class population imbalances we balance the population by randomly selecting a number of images from the most populated classes to keep as many as the least populated class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "successful-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeps the n most populated classes\n",
    "def get_larger_classes(dist_paramsSelect_folder, dist_paramsSelect_name, n):\n",
    "    #ready dataframe\n",
    "    dist_paramsSelect_folder_path = dist_paramsSelect_folder\n",
    "    dist_paramsSelect_path=os.path.join(dist_paramsSelect_folder_path, dist_paramsSelect_name)\n",
    "\n",
    "    df = prepare_features_for_scikit(dist_paramsSelect_path)\n",
    "    class_population=df['Labels'].value_counts(sort=True)\n",
    "\n",
    "    #keeping n most populated classes\n",
    "    class_population=df['Labels'].value_counts(sort=True)\n",
    "    n_most_populated_classes= pd.DataFrame()\n",
    "    \n",
    "    for i in range(n):\n",
    "        n_most_populated_classes = n_most_populated_classes.append(df[df[\"Labels\"]==class_population.index[i]])\n",
    "        \n",
    "    return n_most_populated_classes, df\n",
    "\n",
    "#randomly chooses images of the larger class to balance out dataset\n",
    "def balance_classes(n_most_populated_classes):\n",
    "  class_population = n_most_populated_classes['Labels'].value_counts(sort=True)\n",
    "  smallest_class_population = class_population.iloc[class_population.shape[0]-1]\n",
    "    \n",
    "  balanced_classes = pd.DataFrame()\n",
    "    \n",
    "  for i in range(class_population.shape[0]):\n",
    "      to_append = n_most_populated_classes[n_most_populated_classes[\"Labels\"]==class_population.index[i]].sample(smallest_class_population)\n",
    "      balanced_classes = balanced_classes.append(to_append, ignore_index=True)\n",
    "\n",
    "  return balanced_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-examination",
   "metadata": {},
   "source": [
    "# Balancing classes and cross validating SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "architectural-aspect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.95375</td>\n",
       "      <td>0.04251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mean Accuracy  Standard Deviation\n",
       "0        0.95375             0.04251"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#cross-validate n most populated classes\n",
    "\n",
    "number_of_classes = 3\n",
    "levels = 3\n",
    "dist = \"Normal\"\n",
    "cv_split = 20\n",
    "wavelet = \"db4\"\n",
    "\n",
    "larger_classes, df = get_larger_classes(\"E:\\\\Backups\\\\Work&Uni\\\\University\\\\ML for food authentication\\\\Results_fitting\\\\dist_paramsSelect\\\\New Images v2 (3 classes of 100)\\\\\" ,\\\n",
    "                                        \"dist_paramsSelect wt=db4 levels=3 dist=Normal.mat\",\\\n",
    "                                        3)\n",
    "\n",
    "A=balance_classes(n_most_populated_classes).to_numpy()\n",
    "x=A[:,:-1]\n",
    "y=A[:,-1]\n",
    "\n",
    "model=pipeline.Pipeline((\\\n",
    "                         (\"scaler\",StandardScaler() ),\\\n",
    "                         (\"svm_clf\", svm.SVC(kernel='rbf', gamma=0.01, C=1, decision_function_shape='ovo'))\\\n",
    "                        ))\n",
    "\n",
    "scores = cross_val_score(model, x, y, cv=cv_split)\n",
    "result = pd.DataFrame({\"Mean Accuracy\":[scores.mean()], \"Standard Deviation\":[scores.std()]})\n",
    "\n",
    "print(\"CV results\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-grant",
   "metadata": {},
   "source": [
    "# Repeating many times to validate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "approved-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross-validate n most populated classes\n",
    "def balance_and_cv(n_most_populated_classes, cv_split):\n",
    "    A=balance_classes(n_most_populated_classes).to_numpy()\n",
    "    x=A[:,:-1]\n",
    "    y=A[:,-1]\n",
    "\n",
    "    model=pipeline.Pipeline((\\\n",
    "                             (\"scaler\",StandardScaler() ),\\\n",
    "                             (\"svm_clf\", svm.SVC(kernel='rbf', gamma=0.01, C=1, decision_function_shape='ovo'))\\\n",
    "                            ))\n",
    "\n",
    "    scores = cross_val_score(model, x, y, cv=cv_split)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "developed-entertainment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Mean Accuracy  Standard Deviation\n",
      "count     100.000000          100.000000\n",
      "mean        0.953926            0.027728\n",
      "std         0.005101            0.009977\n",
      "min         0.940588            0.007637\n",
      "25%         0.950458            0.022115\n",
      "50%         0.953791            0.026994\n",
      "75%         0.957124            0.033707\n",
      "max         0.966993            0.060780\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.947320</td>\n",
       "      <td>0.037116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.956993</td>\n",
       "      <td>0.013921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.953791</td>\n",
       "      <td>0.027080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.950719</td>\n",
       "      <td>0.039007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.950654</td>\n",
       "      <td>0.033509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.953856</td>\n",
       "      <td>0.024670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.950654</td>\n",
       "      <td>0.040313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.960392</td>\n",
       "      <td>0.036017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.957124</td>\n",
       "      <td>0.024065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.960458</td>\n",
       "      <td>0.015933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Mean Accuracy  Standard Deviation\n",
       "0        0.947320            0.037116\n",
       "1        0.956993            0.013921\n",
       "2        0.953791            0.027080\n",
       "3        0.950719            0.039007\n",
       "4        0.950654            0.033509\n",
       "..            ...                 ...\n",
       "95       0.953856            0.024670\n",
       "96       0.950654            0.040313\n",
       "97       0.960392            0.036017\n",
       "98       0.957124            0.024065\n",
       "99       0.960458            0.015933\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3 balanced classes wt=db4 levels=3 dist=Normal\n",
    "results=pd.DataFrame(columns=[\"Mean Accuracy\", \"Standard Deviation\"])\n",
    "larger_classes, df = get_larger_classes(\"E:\\\\Backups\\\\Work&Uni\\\\University\\\\ML for food authentication\\\\Results_fitting\\\\dist_paramsSelect\\\\New Images v2 (3 classes of 100)\\\\\" ,\\\n",
    "                                        \"dist_paramsSelect wt=db4 levels=3 dist=Normal.mat\",\\\n",
    "                                        3)\n",
    "for i in range(100):\n",
    "    scores=balance_and_cv(larger_classes, cv_split=6)\n",
    "    results = results.append(pd.DataFrame({\"Mean Accuracy\":[scores.mean()], \"Standard Deviation\":[scores.std()]}), ignore_index=True)\n",
    "    \n",
    "print(results.describe())\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-discount",
   "metadata": {},
   "source": [
    "# Histogram of the mean accuracy values produced by reapeating the cross validation step many times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "nearby-deputy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Function\n",
    "def train(path_to_distParamsSelect_folder, title_of_mat_file , options, bins=15):\n",
    "    \n",
    "    larger_classes, df = get_larger_classes(\"E:\\\\Backups\\\\Work&Uni\\\\University\\\\ML for food authentication\\\\Results_fitting\\\\dist_paramsSelect\\\\New Images\\\\\", \\\n",
    "                                            \"dist_paramsSelect wt=db4 levels=3 dist=Normal.mat\", \\\n",
    "                                            options[\"Number of Classes\"])\n",
    "\n",
    "    instances_per_class = df['Labels'].value_counts(sort=True).iloc[number_of_classes-1]\n",
    "    options[\"Instances per class\"] = instances_per_class\n",
    "    \n",
    "    results=pd.DataFrame(columns=[\"Mean Accuracy\", \"Standard Deviation\"])\n",
    "\n",
    "    for i in range(options[\"Number of runs\"]):\n",
    "        scores=balance_and_cv(larger_classes, options[\"CV split\"])\n",
    "        results = results.append(pd.DataFrame({\"Mean Accuracy of CV\":[scores.mean()], \"Standard Deviation of CV\":[scores.std()]}), ignore_index=True)\n",
    "\n",
    "    options[\"Mean Accuracy\"] = results.describe()[\"Mean Accuracy of CV\"].iloc[1]\n",
    "    options[\"Standard Deviation of Mean Accuracy\"] = results.describe()[\"Standard Deviation of CV\"].iloc[1]\n",
    "    all_results = pd.DataFrame(columns=[\"Number of Classes\", \"Instances per class\", \"Distribution\", \"Wavelet\", \"Levels\", \"Number of runs\", \"CV split\" ,\"Mean Accuracy\", \"Standard Deviation of Mean Accuracy\"])\n",
    "    all_results = all_results.append(options, ignore_index=True)\n",
    "    results.hist(\"Mean Accuracy of CV\", bins=bins)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "environmental-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To keep all results\n",
    "all_results = pd.DataFrame(columns=[\"Number of Classes\", \"Instances per class\", \"Distribution\", \"Wavelet\", \"Levels\", \"Number of runs\", \"CV split\" ,\"Mean Accuracy\", \"Standard Deviation of Mean Accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bulgarian-liquid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#4 most populated classes wt=db4 levels=3 Normal\n",
    "number_of_classes = 3\n",
    "levels = 3\n",
    "dist = \"Normal\"\n",
    "number_of_runs = 1000\n",
    "cv_split = 20\n",
    "wavelet = \"db4\"\n",
    "\n",
    "options = {\"Number of Classes\":number_of_classes,\\\n",
    "           \"Distribution\":dist,\\\n",
    "           \"Wavelet\":wavelet,\\\n",
    "           \"Levels\":levels,\\\n",
    "           \"Number of runs\":number_of_runs,\\\n",
    "           \"CV split\":cv_split}\n",
    "\n",
    "all_results = all_results.append( train(\"E:\\\\Backups\\\\Work&Uni\\\\University\\\\ML for food authentication\\\\Results_fitting\\\\dist_paramsSelect\\\\New Images v2 (3 classes of 100)\\\\\" ,\\\n",
    "                                        \"dist_paramsSelect wt=db4 levels=3 dist=Normal.mat\",\\\n",
    "                                        options),\\\n",
    "                                  ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-cotton",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
